# -*- coding: utf-8 -*-
"""tensorflow_resnet50_99_95.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z1q_e4TC7c_YXiKlRZ1dPfTrN1R9QcJa
"""



import tensorflow as tf
from tensorflow import keras
import matplotlib.image as mpimg
import os
import time
import numpy as np
import matplotlib.pyplot as plt
import PIL

tf.enable_eager_execution()

os.chdir("/content/drive/My Drive/Projects/Gesturec/data/leapGestRecog/")

classes = os.listdir()

int_classes = list(range(len(classes)))


filenames = []
labels = []
for idx,gesture in enumerate(classes):
  tmp = os.listdir(gesture)
  tmp = [gesture+"/"+i for i in tmp]
  filenames = filenames + tmp
  labels = labels + [idx]*(len(tmp))

filenames[-5:],labels[-5:]

from sklearn.model_selection import train_test_split

train_ds, val_ds, label_train, label_val = train_test_split(filenames, labels, test_size=0.2, random_state=42)

data_length = len(filenames);data_length

image_size = 224 # All images will be resized to 160x160
batch_size = 32

def tfdata_generator(filenames, labels, is_training=True, batch_size=32):
    '''Construct a data generator using tf.Dataset'''

    def parse_function(filename, label):
      image_string = tf.read_file(filename)
  
      # Don't use tf.image.decode_image, or the output shape will be undefined
      image = tf.image.decode_png(image_string, channels=3)
  
      # This will convert to float values in [0, 1]
      image = tf.image.convert_image_dtype(image, tf.float32)
  
      image = tf.image.resize_images(image, [image_size, image_size])
      
      label = tf.one_hot(tf.cast(label, tf.uint8), 10)
        
      return image, label
    
    def train_preprocess(image, label):
      image = tf.image.random_flip_left_right(image)
      image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)
      image = tf.image.random_saturation(image, lower=0.5, upper=1.5)
    
        # Make sure the image is still in [0, 1]
      image = tf.clip_by_value(image, 0.0, 1.0)
    
      return image, label

    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    if is_training:
        dataset = dataset.shuffle(len(filenames))  # depends on sample size
        
    dataset = dataset.map(parse_function, num_parallel_calls=4)
    dataset = dataset.map(train_preprocess, num_parallel_calls=4)
    dataset = dataset.batch(batch_size,drop_remainder=True if is_training else False)
    
    dataset = dataset.repeat()
    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)

    return dataset

training_set = tfdata_generator(train_ds, label_train)
testing_set  = tfdata_generator(val_ds, label_val, is_training=False)

IMG_SHAPE = (image_size, image_size, 3)

base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,include_top=False,  weights='imagenet')

base_model.trainable = False

model = tf.keras.Sequential([
  base_model,
  keras.layers.GlobalAveragePooling2D(),
  keras.layers.Dense(10, activation='softmax')
])

model.compile('adam', 'categorical_crossentropy', metrics=['acc'])

model.fit(
      training_set.make_one_shot_iterator(),
      steps_per_epoch=16000 // 32,
      epochs=5,
      validation_data=testing_set.make_one_shot_iterator(),
      validation_steps=4000 //32,
      verbose = 1)

model.save_weights('./checkpoints/leap_resnet50')

checkpoint_dir = '../../data/'
os.makedirs(checkpoint_dir, exist_ok=True)
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
root = tf.train.Checkpoint(optimizer=optimizer,
                           model=model,
                           optimizer_step=tf.train.get_or_create_global_step())

root.save(checkpoint_prefix)

for a,b in val_dataset.take(-1):
  prediction = model.predict(a,steps=1)
  res = tf.argmax(tf.nn.softmax(prediction),axis=1)

res.numpy() == b.numpy()


